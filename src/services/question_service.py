"""
Ø®Ø¯Ù…Ø© Ø¥Ø¯Ø§Ø±Ø© Ø§Ù„Ø£Ø³Ø¦Ù„Ø©
ØªØ¯Ø¹Ù… Ø§Ù„ØªØ­Ù…ÙŠÙ„ Ù…Ù† GitHub Ø£Ùˆ Ø§Ù„Ù…Ù„ÙØ§Øª Ø§Ù„Ù…Ø­Ù„ÙŠØ© + metadata
"""

import json
import random
import requests
import re
from pathlib import Path
from datetime import datetime, timedelta
import logging

logger = logging.getLogger(__name__)

class QuestionService:
    """Ø®Ø¯Ù…Ø© Ø¥Ø¯Ø§Ø±Ø© Ø§Ù„Ø£Ø³Ø¦Ù„Ø© Ù…Ø¹ Ø¯Ø¹Ù… GitHub Ùˆ metadata"""
    
    def __init__(self, questions_dir: str, github_url: str = None, 
                 use_online: bool = False, cache_enabled: bool = True,
                 cache_duration: int = 60):
        """
        ØªÙ‡ÙŠØ¦Ø© Ø®Ø¯Ù…Ø© Ø§Ù„Ø£Ø³Ø¦Ù„Ø©
        
        Args:
            questions_dir: Ù…Ø³Ø§Ø± Ø§Ù„Ù…Ø¬Ù„Ø¯ Ø§Ù„Ù…Ø­Ù„ÙŠ
            github_url: Ø±Ø§Ø¨Ø· GitHub Raw
            use_online: Ø§Ø³ØªØ®Ø¯Ø§Ù… GitHub Ø£Ù… Ø§Ù„Ù…Ù„ÙØ§Øª Ø§Ù„Ù…Ø­Ù„ÙŠØ©
            cache_enabled: ØªÙØ¹ÙŠÙ„ Ø§Ù„Ù€ Cache
            cache_duration: Ù…Ø¯Ø© Ø§Ù„Ù€ Cache Ø¨Ø§Ù„Ø¯Ù‚Ø§Ø¦Ù‚
        """
        self.questions_dir = Path(questions_dir)
        self.github_url = github_url
        self.use_online = use_online
        self.cache_enabled = cache_enabled
        self.cache_duration = timedelta(minutes=cache_duration)
        
        # Ù…Ø®Ø²Ù† Ø§Ù„Ù€ Cache ÙÙŠ Ø§Ù„Ø°Ø§ÙƒØ±Ø©
        self._cache = {}
        self._cache_timestamps = {}
    
    def _is_cache_valid(self, key: str) -> bool:
        """Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ØµÙ„Ø§Ø­ÙŠØ© Ø§Ù„Ù€ Cache"""
        if not self.cache_enabled:
            return False
        
        if key not in self._cache_timestamps:
            return False
        
        elapsed = datetime.now() - self._cache_timestamps[key]
        return elapsed < self.cache_duration
    
    def _get_from_cache(self, key: str):
        """Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù…Ù† Ø§Ù„Ù€ Cache"""
        if self._is_cache_valid(key):
            logger.info(f"ğŸ“¦ ØªØ­Ù…ÙŠÙ„ Ù…Ù† Cache: {key}")
            return self._cache.get(key)
        return None
    
    def _save_to_cache(self, key: str, data):
        """Ø­ÙØ¸ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª ÙÙŠ Ø§Ù„Ù€ Cache"""
        if self.cache_enabled:
            self._cache[key] = data
            self._cache_timestamps[key] = datetime.now()
            logger.info(f"ğŸ’¾ Ø­ÙØ¸ ÙÙŠ Cache: {key}")
    
    def load_questions_from_github(self, filepath: str) -> dict:
        """
        ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø£Ø³Ø¦Ù„Ø© Ù…Ù† GitHub Ù…Ø¹ Ø¯Ø¹Ù… metadata
        
        Args:
            filepath: Ø§Ù„Ù…Ø³Ø§Ø± Ø§Ù„Ù†Ø³Ø¨ÙŠ ÙÙŠ Ø§Ù„Ø±ÙŠØ¨Ùˆ
        
        Returns:
            dict: {'metadata': {...}, 'questions': [...]}
        """
        # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„Ù€ Cache
        cached = self._get_from_cache(filepath)
        if cached:
            return cached
        
        url = f"{self.github_url}/{filepath}"
        
        try:
            logger.info(f"ğŸŒ ØªØ­Ù…ÙŠÙ„ Ù…Ù† GitHub: {url}")
            response = requests.get(url, timeout=10)
            response.raise_for_status()
            
            data = response.json()
            
            # Ø¯Ø¹Ù… Ø§Ù„ØµÙŠØºØªÙŠÙ†: Ø§Ù„Ø¬Ø¯ÙŠØ¯Ø© (Ù…Ø¹ metadata) ÙˆØ§Ù„Ù‚Ø¯ÙŠÙ…Ø© (Ù…ØµÙÙˆÙØ© Ù…Ø¨Ø§Ø´Ø±Ø©)
            if isinstance(data, dict) and 'questions' in data:
                # ØµÙŠØºØ© Ø¬Ø¯ÙŠØ¯Ø© Ù…Ø¹ metadata
                result = data
                logger.info(f"âœ… ØªÙ… ØªØ­Ù…ÙŠÙ„ {len(result['questions'])} Ø³Ø¤Ø§Ù„ Ù…Ø¹ metadata")
            elif isinstance(data, list):
                # ØµÙŠØºØ© Ù‚Ø¯ÙŠÙ…Ø© (Ù…ØµÙÙˆÙØ© Ù…Ø¨Ø§Ø´Ø±Ø©)
                result = {
                    'metadata': {
                        'title': 'Unknown',
                        'title_ar': 'ØºÙŠØ± Ù…Ø¹Ø±ÙˆÙ',
                        'description': '',
                        'difficulty': 'medium'
                    },
                    'questions': data
                }
                logger.info(f"âœ… ØªÙ… ØªØ­Ù…ÙŠÙ„ {len(data)} Ø³Ø¤Ø§Ù„ (ØµÙŠØºØ© Ù‚Ø¯ÙŠÙ…Ø©)")
            else:
                raise ValueError("Ø§Ù„Ù…Ù„Ù ÙŠØ¬Ø¨ Ø£Ù† ÙŠÙƒÙˆÙ† Ù…ØµÙÙˆÙØ© Ø£Ùˆ object Ù…Ø¹ Ø­Ù‚Ù„ 'questions'")
            
            # Ø­ÙØ¸ ÙÙŠ Ø§Ù„Ù€ Cache
            self._save_to_cache(filepath, result)
            
            return result
        
        except requests.RequestException as e:
            logger.error(f"âŒ ÙØ´Ù„ Ø§Ù„ØªØ­Ù…ÙŠÙ„ Ù…Ù† GitHub: {e}")
            raise ConnectionError(f"ÙØ´Ù„ Ø§Ù„Ø§ØªØµØ§Ù„ Ø¨Ù€ GitHub: {str(e)}")
        
        except json.JSONDecodeError as e:
            logger.error(f"âŒ Ø®Ø·Ø£ ÙÙŠ JSON Ù…Ù† GitHub: {e}")
            raise ValueError(f"Ù…Ù„Ù JSON ØºÙŠØ± ØµØ§Ù„Ø­: {str(e)}")
    
    def load_questions_from_local(self, filename: str) -> dict:
        """
        ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø£Ø³Ø¦Ù„Ø© Ù…Ù† Ù…Ù„Ù Ù…Ø­Ù„ÙŠ
        
        Args:
            filename: Ø§Ø³Ù… Ø§Ù„Ù…Ù„Ù (Ù…Ø«Ù„ 'ai/ch1.json')
        
        Returns:
            dict: {'metadata': {...}, 'questions': [...]}
        """
        filepath = self.questions_dir / filename
        
        if not filepath.exists():
            logger.error(f"âŒ Ø§Ù„Ù…Ù„Ù ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯: {filepath}")
            raise FileNotFoundError(f"Ø§Ù„Ù…Ù„Ù ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯: {filename}")
        
        try:
            with open(filepath, 'r', encoding='utf-8') as f:
                data = json.load(f)
            
            # Ø¯Ø¹Ù… Ø§Ù„ØµÙŠØºØªÙŠÙ†
            if isinstance(data, dict) and 'questions' in data:
                result = data
                logger.info(f"âœ… ØªÙ… ØªØ­Ù…ÙŠÙ„ {len(result['questions'])} Ø³Ø¤Ø§Ù„ Ù…Ø¹ metadata Ù…Ù† Ø§Ù„Ù…Ù„Ù Ø§Ù„Ù…Ø­Ù„ÙŠ")
            elif isinstance(data, list):
                result = {
                    'metadata': {
                        'title': 'Unknown',
                        'title_ar': 'ØºÙŠØ± Ù…Ø¹Ø±ÙˆÙ'
                    },
                    'questions': data
                }
                logger.info(f"âœ… ØªÙ… ØªØ­Ù…ÙŠÙ„ {len(data)} Ø³Ø¤Ø§Ù„ (ØµÙŠØºØ© Ù‚Ø¯ÙŠÙ…Ø©) Ù…Ù† Ø§Ù„Ù…Ù„Ù Ø§Ù„Ù…Ø­Ù„ÙŠ")
            else:
                raise ValueError("Ø§Ù„Ù…Ù„Ù ÙŠØ¬Ø¨ Ø£Ù† ÙŠÙƒÙˆÙ† Ù…ØµÙÙˆÙØ© Ø£Ùˆ object Ù…Ø¹ Ø­Ù‚Ù„ 'questions'")
            
            return result
        
        except json.JSONDecodeError as e:
            logger.error(f"âŒ Ø®Ø·Ø£ ÙÙŠ JSON: {e}")
            raise
        except Exception as e:
            logger.error(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ø§Ù„ØªØ­Ù…ÙŠÙ„: {e}")
            raise
    
    def get_available_parts_from_github(self, subject: str, folder_name: str) -> list:
        """
        Ø§ÙƒØªØ´Ø§Ù Ø¬Ù…ÙŠØ¹ Ø§Ù„Ù…Ù„ÙØ§Øª Ø§Ù„Ù…ØªØ§Ø­Ø© ÙÙŠ Ù…Ø¬Ù„Ø¯ Ø§Ù„Ù…Ø§Ø¯Ø© Ø¹Ù„Ù‰ GitHub
        + ØªØ­Ù…ÙŠÙ„ metadata Ù„ÙƒÙ„ Ù…Ù„Ù Ù„Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø§Ù„Ø¹Ù†Ø§ÙˆÙŠÙ†
        
        Args:
            subject: Ù…ÙØªØ§Ø­ Ø§Ù„Ù…Ø§Ø¯Ø© (Ù…Ø«Ù„ 'ai')
            folder_name: Ø§Ø³Ù… Ø§Ù„Ù…Ø¬Ù„Ø¯ Ø¹Ù„Ù‰ GitHub (Ù…Ø«Ù„ 'ai_quizzes')
        
        Returns:
            Ù‚Ø§Ø¦Ù…Ø© Ø¨Ø§Ù„Ø£Ø¬Ø²Ø§Ø¡ Ù…Ø¹ Ø¹Ù†Ø§ÙˆÙŠÙ†Ù‡Ø§ Ù…Ù† metadata
        """
        try:
            # GitHub API Ù„Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„Ù…Ù„ÙØ§Øª ÙÙŠ Ø§Ù„Ù…Ø¬Ù„Ø¯
            api_url = f"https://api.github.com/repos/AboALhasanx/json-files/contents/{folder_name}"
            
            logger.info(f"ğŸ” Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ø§Ù„Ù…Ù„ÙØ§Øª ÙÙŠ: {folder_name}")
            response = requests.get(api_url, timeout=10)
            response.raise_for_status()
            
            files_data = response.json()
            
            # ÙÙ„ØªØ±Ø© Ù…Ù„ÙØ§Øª JSON ÙÙ‚Ø·
            parts = []
            for file_info in files_data:
                if file_info['name'].endswith('.json'):
                    filename = file_info['name']
                    
                    # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø±Ù‚Ù… Ø§Ù„Ø¬Ø²Ø¡ Ù…Ù† Ø§Ø³Ù… Ø§Ù„Ù…Ù„Ù
                    match = re.search(r'_pt(\d+)\.json$', filename)
                    if match:
                        part_num = match.group(1)
                        filepath = f'{folder_name}/{filename}'
                        
                        # Ù…Ø­Ø§ÙˆÙ„Ø© ØªØ­Ù…ÙŠÙ„ metadata Ù„Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø§Ù„Ø¹Ù†ÙˆØ§Ù†
                        try:
                            part_data = self.load_questions_from_github(filepath)
                            metadata = part_data.get('metadata', {})
                            title_ar = metadata.get('title_ar', f'Ø§Ù„Ø¬Ø²Ø¡ {part_num}')
                            title_en = metadata.get('title', f'Part {part_num}')
                        except Exception as e:
                            logger.warning(f"âš ï¸ ÙØ´Ù„ ØªØ­Ù…ÙŠÙ„ metadata Ù…Ù† {filename}: {e}")
                            title_ar = f'Ø§Ù„Ø¬Ø²Ø¡ {part_num}'
                            title_en = f'Part {part_num}'
                        
                        parts.append({
                            'part': f'pt{part_num}',
                            'file': filename,
                            'filepath': filepath,
                            'display': f'Ø§Ù„Ø¬Ø²Ø¡ {part_num}',  # fallback
                            'title_ar': title_ar,  # Ø§Ù„Ø¹Ù†ÙˆØ§Ù† Ø§Ù„Ø­Ù‚ÙŠÙ‚ÙŠ Ù…Ù† metadata
                            'title_en': title_en,
                            'part_num': int(part_num)
                        })
            
            # ØªØ±ØªÙŠØ¨ Ø­Ø³Ø¨ Ø±Ù‚Ù… Ø§Ù„Ø¬Ø²Ø¡
            parts.sort(key=lambda x: x['part_num'])
            
            logger.info(f"âœ… ØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ {len(parts)} Ø¬Ø²Ø¡ ÙÙŠ {folder_name}")
            return parts
        
        except requests.RequestException as e:
            logger.error(f"âŒ ÙØ´Ù„ Ø§Ù„Ø§ØªØµØ§Ù„ Ø¨Ù€ GitHub API: {e}")
            return []
        except Exception as e:
            logger.error(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ø§ÙƒØªØ´Ø§Ù Ø§Ù„Ù…Ù„ÙØ§Øª: {e}")
            return []
    
    def load_questions_for_part(self, subject: str, part_filepath: str) -> dict:
        """
        ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø£Ø³Ø¦Ù„Ø© Ù„Ø¬Ø²Ø¡ Ù…Ø­Ø¯Ø¯ Ù…Ù† Ù…Ø§Ø¯Ø©
        
        Args:
            subject: Ù…ÙØªØ§Ø­ Ø§Ù„Ù…Ø§Ø¯Ø© (Ù…Ø«Ù„ 'ai')
            part_filepath: Ø§Ù„Ù…Ø³Ø§Ø± Ø§Ù„ÙƒØ§Ù…Ù„ Ù„Ù„Ù…Ù„Ù Ø¹Ù„Ù‰ GitHub
        
        Returns:
            dict: {'metadata': {...}, 'questions': [...]}
        """
        if self.use_online and self.github_url:
            # Ø§Ù„ØªØ­Ù…ÙŠÙ„ Ù…Ù† GitHub
            try:
                return self.load_questions_from_github(part_filepath)
            
            except (ConnectionError, ValueError) as e:
                logger.warning(f"âš ï¸ ÙØ´Ù„ Ø§Ù„ØªØ­Ù…ÙŠÙ„ Ù…Ù† GitHub: {e}")
                raise
        
        else:
            # Ø§Ù„ØªØ­Ù…ÙŠÙ„ Ù…Ù† Ø§Ù„Ù…Ù„ÙØ§Øª Ø§Ù„Ù…Ø­Ù„ÙŠØ©
            local_path = f"{subject}/{part_filepath.split('/')[-1]}"
            return self.load_questions_from_local(local_path)
    
    def get_random_questions(self, questions: list, count: int) -> list:
        """Ø§Ø®ØªÙŠØ§Ø± Ø£Ø³Ø¦Ù„Ø© Ø¹Ø´ÙˆØ§Ø¦ÙŠØ©"""
        actual_count = min(len(questions), count)
        
        if actual_count < count:
            logger.warning(f"âš ï¸ Ø¹Ø¯Ø¯ Ø§Ù„Ø£Ø³Ø¦Ù„Ø© Ø§Ù„Ù…ØªØ§Ø­Ø© ({len(questions)}) Ø£Ù‚Ù„ Ù…Ù† Ø§Ù„Ù…Ø·Ù„ÙˆØ¨ ({count})")
        
        return random.sample(questions, actual_count)
    
    def validate_question(self, question: dict) -> bool:
        """Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ØµØ­Ø© Ø¨Ù†ÙŠØ© Ø§Ù„Ø³Ø¤Ø§Ù„"""
        required_fields = ['question', 'options', 'correct_option_id']
        
        for field in required_fields:
            if field not in question:
                logger.error(f"âŒ Ø­Ù‚Ù„ Ù…ÙÙ‚ÙˆØ¯: {field}")
                return False
        
        # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø·ÙˆÙ„ Ø§Ù„Ø³Ø¤Ø§Ù„
        if len(question['question']) > 300:
            logger.error(f"âŒ Ø§Ù„Ø³Ø¤Ø§Ù„ Ø·ÙˆÙŠÙ„ Ø¬Ø¯Ø§Ù‹ ({len(question['question'])} Ø­Ø±Ù)")
            return False
        
        # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø¹Ø¯Ø¯ Ø§Ù„Ø®ÙŠØ§Ø±Ø§Øª
        if len(question['options']) < 2 or len(question['options']) > 10:
            logger.error("âŒ ÙŠØ¬Ø¨ Ø£Ù† ÙŠØ­ØªÙˆÙŠ Ø§Ù„Ø³Ø¤Ø§Ù„ Ø¹Ù„Ù‰ 2-10 Ø®ÙŠØ§Ø±Ø§Øª")
            return False
        
        # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø·ÙˆÙ„ ÙƒÙ„ Ø®ÙŠØ§Ø±
        for i, option in enumerate(question['options']):
            if len(option) > 100:
                logger.error(f"âŒ Ø§Ù„Ø®ÙŠØ§Ø± {i+1} Ø·ÙˆÙŠÙ„ Ø¬Ø¯Ø§Ù‹ ({len(option)} Ø­Ø±Ù): {option[:50]}...")
                return False
        
        # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ØµØ­Ø© Ø±Ù‚Ù… Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø©
        if not (0 <= question['correct_option_id'] < len(question['options'])):
            logger.error("âŒ Ø±Ù‚Ù… Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø© Ø§Ù„ØµØ­ÙŠØ­Ø© Ø®Ø§Ø±Ø¬ Ø§Ù„Ù†Ø·Ø§Ù‚")
            return False
        
        return True
    
    def shuffle_question_options(self, question: dict) -> dict:
        """
        Ø®Ù„Ø· Ø®ÙŠØ§Ø±Ø§Øª Ø§Ù„Ø³Ø¤Ø§Ù„ Ø¨Ø´ÙƒÙ„ Ø¹Ø´ÙˆØ§Ø¦ÙŠ
        Ù…Ø¹ ØªØ­Ø¯ÙŠØ« correct_option_id Ù„ÙŠØ´ÙŠØ± Ù„Ù„Ø®ÙŠØ§Ø± Ø§Ù„ØµØ­ÙŠØ­ Ø§Ù„Ø¬Ø¯ÙŠØ¯
        
        Args:
            question: Ø§Ù„Ø³Ø¤Ø§Ù„ Ø§Ù„Ø£ØµÙ„ÙŠ
        
        Returns:
            dict: Ø§Ù„Ø³Ø¤Ø§Ù„ Ù…Ø¹ Ø®ÙŠØ§Ø±Ø§Øª Ù…Ø®Ù„ÙˆØ·Ø©
        """
        import copy
        
        # Ù†Ø³Ø® Ø¹Ù…ÙŠÙ‚Ø© Ù„ØªØ¬Ù†Ø¨ ØªØ¹Ø¯ÙŠÙ„ Ø§Ù„Ø£ØµÙ„
        shuffled_q = copy.deepcopy(question)
        
        # Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø© Ø§Ù„ØµØ­ÙŠØ­Ø© Ø§Ù„Ø­Ø§Ù„ÙŠØ©
        correct_option_text = shuffled_q['options'][shuffled_q['correct_option_id']]
        
        # Ø®Ù„Ø· Ø§Ù„Ø®ÙŠØ§Ø±Ø§Øª
        random.shuffle(shuffled_q['options'])
        
        # Ø¥ÙŠØ¬Ø§Ø¯ Ø§Ù„Ù…ÙˆÙ‚Ø¹ Ø§Ù„Ø¬Ø¯ÙŠØ¯ Ù„Ù„Ø¥Ø¬Ø§Ø¨Ø© Ø§Ù„ØµØ­ÙŠØ­Ø©
        new_correct_index = shuffled_q['options'].index(correct_option_text)
        shuffled_q['correct_option_id'] = new_correct_index
        
        return shuffled_q
    
    def shuffle_all_questions(self, questions: list) -> list:
        """
        Ø®Ù„Ø· Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø£Ø³Ø¦Ù„Ø© ÙˆØ®ÙŠØ§Ø±Ø§ØªÙ‡Ø§ Ø¨Ø´ÙƒÙ„ Ø¹Ø´ÙˆØ§Ø¦ÙŠ
        
        Args:
            questions: Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„Ø£Ø³Ø¦Ù„Ø© Ø§Ù„Ø£ØµÙ„ÙŠØ©
        
        Returns:
            list: Ù‚Ø§Ø¦Ù…Ø© Ù…Ø®Ù„ÙˆØ·Ø© Ù…Ø¹ Ø®ÙŠØ§Ø±Ø§Øª Ù…Ø®Ù„ÙˆØ·Ø©
        """
        # Ø®Ù„Ø· ØªØ±ØªÙŠØ¨ Ø§Ù„Ø£Ø³Ø¦Ù„Ø©
        shuffled_questions = random.sample(questions, len(questions))
        
        # Ø®Ù„Ø· Ø®ÙŠØ§Ø±Ø§Øª ÙƒÙ„ Ø³Ø¤Ø§Ù„
        for i in range(len(shuffled_questions)):
            shuffled_questions[i] = self.shuffle_question_options(shuffled_questions[i])
        
        logger.info(f"ğŸ”€ ØªÙ… Ø®Ù„Ø· {len(shuffled_questions)} Ø³Ø¤Ø§Ù„ Ù…Ø¹ Ø®ÙŠØ§Ø±Ø§ØªÙ‡Ù…")
        return shuffled_questions


    def clear_cache(self):
        """Ù…Ø³Ø­ Ø§Ù„Ù€ Cache"""
        self._cache.clear()
        self._cache_timestamps.clear()
        logger.info("ğŸ—‘ï¸ ØªÙ… Ù…Ø³Ø­ Cache")
